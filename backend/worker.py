import asyncio
import logging
import os
import sys
import boto3
import io
import time
import bleach
import signal
import json
import redis.asyncio as aioredis
from typing import Dict, Any
from dotenv import load_dotenv
from telethon import TelegramClient, types
from telethon.errors import ChannelPrivateError, FloodWaitError
from sqlalchemy import select, distinct, update
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.dialects.postgresql import insert

from database.engine import session_maker, create_db
from database.models import Channel, Post, BackfillRequest, Subscription
from telethon.sessions import StringSession
from PIL import Image
from html import escape
from markdown_it import MarkdownIt

print("üîÑ WORKER.PY –ó–ê–ì–†–£–ñ–ê–ï–¢–°–Ø...")
print(f"Python version: {sys.version}")

try:
    # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    print("üìã –ó–∞–≥—Ä—É–∂–∞—é –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    load_dotenv()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    print("üîç –ü—Ä–æ–≤–µ—Ä—è—é –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    
    API_ID_STR = os.getenv("API_ID")
    API_HASH = os.getenv("API_HASH") 
    SESSION_STRING = os.getenv("TELETHON_SESSION")
    REDIS_URL = os.getenv("REDIS_URL") or os.getenv("REDIS_PUBLIC_URL")
    
    print(f"  API_ID: {'‚úÖ' if API_ID_STR else '‚ùå'}")
    print(f"  API_HASH: {'‚úÖ' if API_HASH else '‚ùå'}")
    print(f"  SESSION_STRING: {'‚úÖ' if SESSION_STRING else '‚ùå'}")
    print(f"  REDIS_URL: {'‚úÖ' if REDIS_URL else '‚ùå'}")
    
    # –ü–∞—Ä—Å–∏–Ω–≥ API_ID
    try:
        API_ID = int(API_ID_STR) if API_ID_STR else None
        print(f"  API_ID parsed: {'‚úÖ' if API_ID else '‚ùå'}")
    except Exception as e:
        print(f"  ‚ùå API_ID parse error: {e}")
        API_ID = None
    
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    try:
        client = TelegramClient(StringSession(SESSION_STRING or ""), API_ID, API_HASH) if (SESSION_STRING and API_ID is not None and API_HASH) else None
        print(f"  Telethon client: {'‚úÖ' if client else '‚ùå'}")
    except Exception as e:
        print(f"  ‚ùå Telethon client error: {e}")
        client = None

    class RedisPublisher: # type: ignore
        def __init__(self, redis_url: str):
            self.redis_url, self._pool, self._lock = redis_url, None, asyncio.Lock()
        async def get_connection(self):
            if self._pool is None:
                async with self._lock:
                    if self._pool is None: self._pool = aioredis.ConnectionPool.from_url(self.redis_url, max_connections=20, retry_on_timeout=True)
            return aioredis.Redis(connection_pool=self._pool)
        async def publish(self, channel: str, message: str):
            try: await (await self.get_connection()).publish(channel, message)
            except Exception as e: logging.error(f"Redis publish error: {e}")
        async def close(self):
            if self._pool: await self._pool.disconnect()

    try:
        redis_publisher = RedisPublisher(REDIS_URL) if REDIS_URL else None
        print(f"  Redis publisher: {'‚úÖ' if redis_publisher else '‚ùå'}")
    except Exception as e:
        print(f"  ‚ùå Redis publisher error: {e}")
        redis_publisher = None
    
    print("‚úÖ worker.py —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
    
except Exception as e:
    print(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –ó–ê–ì–†–£–ó–ö–ï worker.py: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# --- –ù–ê–°–¢–†–û–ô–ö–ê ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
load_dotenv()

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
API_ID_STR, API_HASH, SESSION_STRING = os.getenv("API_ID"), os.getenv("API_HASH"), os.getenv("TELETHON_SESSION")
S3_BUCKET_NAME, S3_REGION = os.getenv("S3_BUCKET_NAME"), os.getenv("S3_REGION")
AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY_ID"), os.getenv("AWS_SECRET_ACCESS_KEY")
REDIS_URL = os.getenv("REDIS_URL") or os.getenv("REDIS_PUBLIC_URL")
API_ID = int(API_ID_STR) if API_ID_STR else None
POST_LIMIT, SLEEP_TIME = 20, 300

md_parser = MarkdownIt('commonmark', {'breaks': True, 'html': False, 'linkify': True})
shutdown_event = asyncio.Event()

client = TelegramClient(StringSession(SESSION_STRING or ""), API_ID, API_HASH) if (SESSION_STRING and API_ID is not None and API_HASH) else None
s3_client = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY_ID, aws_secret_access_key=AWS_SECRET_ACCESS_KEY, region_name=S3_REGION)

# --- THREAD-SAFE –ö–õ–ê–°–°–´ (–ò–°–ü–†–ê–í–õ–ï–ù–û) ---
class ThreadSafeEntityCache:
    def __init__(self, max_size: int = 500):
        self._cache: Dict[str, Any] = {}
        self._access_times: Dict[str, float] = {}
        self._locks: Dict[str, asyncio.Lock] = {}
        self._max_size = max_size
        self._main_lock = asyncio.Lock()
    async def get_entity(self, cache_key: str, fetch_func):
        if cache_key in self._cache:
            async with self._main_lock:
                self._access_times[cache_key] = time.time()
                if len(self._cache) >= self._max_size:
                    await self._cleanup_if_needed()
            return self._cache[cache_key]
        async with self._main_lock:
            if cache_key not in self._locks: self._locks[cache_key] = asyncio.Lock()
            lock = self._locks[cache_key]
        async with lock:
            if cache_key in self._cache:
                async with self._main_lock: self._access_times[cache_key] = time.time()
                return self._cache[cache_key]
            await self._cleanup_if_needed()
            try:
                entity = await fetch_func()
                async with self._main_lock: self._cache[cache_key], self._access_times[cache_key] = entity, time.time()
                return entity
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è entity –¥–ª—è {cache_key}: {e}")
                return None
    async def _cleanup_if_needed(self):
        # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ–¥ main_lock, –ø–æ—ç—Ç–æ–º—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ –Ω—É–∂–Ω–∞
        if len(self._cache) >= self._max_size:
            to_remove = sorted(self._access_times.items(), key=lambda x: x[1])[:self._max_size // 5]
            for key, _ in to_remove:
                self._cache.pop(key, None); self._access_times.pop(key, None); self._locks.pop(key, None)
class WorkerStats:
    def __init__(self):
        self.start_time = time.time()
        self.processed_channels, self.processed_posts, self.errors = 0, 0, 0
        self._lock = asyncio.Lock()
    async def increment_posts(self, count: int):
        async with self._lock: self.processed_posts += count
    async def increment_errors(self, count: int = 1):
        async with self._lock: self.errors += count
    async def set_channels(self, count: int):
        async with self._lock: self.processed_channels = count
    async def get_stats(self) -> dict:
        async with self._lock:
            return {'start_time': self.start_time, 'processed_channels': self.processed_channels, 'processed_posts': self.processed_posts, 'errors': self.errors}
class RedisPublisher:
    def __init__(self, redis_url: str):
        self.redis_url, self._pool, self._lock = redis_url, None, asyncio.Lock()
    async def get_connection(self):
        if self._pool is None:
            async with self._lock:
                if self._pool is None: self._pool = aioredis.ConnectionPool.from_url(self.redis_url, max_connections=20, retry_on_timeout=True)
        return aioredis.Redis(connection_pool=self._pool)
    async def publish(self, channel: str, message: str):
        try: await (await self.get_connection()).publish(channel, message)
        except Exception as e: logging.error(f"Redis publish error: {e}")
    async def close(self):
        if self._pool: await self._pool.disconnect()

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï INSTANCES ---
entity_cache = ThreadSafeEntityCache()
worker_stats = WorkerStats()
redis_publisher = RedisPublisher(REDIS_URL) if REDIS_URL else None
s3_semaphore = asyncio.Semaphore(10)

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def signal_handler(signum, frame): shutdown_event.set()
def process_text(text: str | None) -> str | None:
    if not text: return None
    try:
        html = md_parser.renderInline(text)
        return bleach.clean(html.replace('<a href', '<a target="_blank" rel="noopener noreferrer" href'), tags=['a', 'b', 'strong', 'i', 'em', 'pre', 'code', 'br', 's', 'u', 'blockquote'], attributes={'a': ['href', 'title', 'target', 'rel']})
    except Exception: return escape(text or "").replace('\n', '<br>')
async def get_cached_entity(channel: Channel):
    async def fetcher():
        if client is None:
            logging.error("Telethon client is not initialized.")
            return None
        entity = await client.get_entity(channel.username or int(channel.id))
        return entity[0] if isinstance(entity, list) else entity
    return await entity_cache.get_entity(str(channel.id), fetcher)
async def upload_avatar_to_s3(telethon_client: TelegramClient, channel_entity) -> str | None:
    try:
        file_key, file_in_memory = f"avatars/{channel_entity.id}.jpg", io.BytesIO()
        await telethon_client.download_profile_photo(channel_entity, file=file_in_memory)
        if file_in_memory.getbuffer().nbytes == 0: return None
        file_in_memory.seek(0); s3_client.upload_fileobj(file_in_memory, S3_BUCKET_NAME, file_key, ExtraArgs={'ContentType': 'image/jpeg'})
        return f"https://{S3_BUCKET_NAME}.s3.{S3_REGION}.amazonaws.com/{file_key}"
    except Exception as e:
        await worker_stats.increment_errors(); return None

# --- –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò –í–û–†–ö–ï–†–ê ---
async def upload_media_to_s3(message: types.Message, channel_id: int) -> tuple[int, dict | None]:
    # –î–û–ë–ê–í–ò–¢–¨: –ü—Ä–æ–≤–µ—Ä–∫–∞ client
    if client is None:
        logging.error("Telethon client –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        return message.id, None
        
    media_data, media_type = {}, None
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ document
    if isinstance(message.media, types.MessageMediaDocument):
        document = message.media.document
        if document and getattr(document, 'size', 0) > 60 * 1024 * 1024:
            return message.id, None
        
        if isinstance(message.media, types.MessageMediaPhoto): 
            media_type = 'photo'
        elif isinstance(message.media, types.MessageMediaDocument):
            mime = getattr(document, 'mime_type', '') if document else ''
            if mime.startswith('video/'): 
                media_type = 'video'
            elif mime in ['image/gif', 'video/mp4']: 
                media_type = 'gif'
    elif isinstance(message.media, types.MessageMediaPhoto):
        media_type = 'photo'
        
    if not media_type: 
        return message.id, None
        
    try:
        async with s3_semaphore:
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            if media_type == 'photo':
                ext = '.webp'
                content_type = 'image/webp'
            elif media_type == 'gif':
                ext = '.gif'
                content_type = 'image/gif'
            else:  # video
                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–ª—è –≤–∏–¥–µ–æ
                ext = '.dat'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                content_type = 'application/octet-stream'
                
                if isinstance(message.media, types.MessageMediaDocument) and message.media.document:
                    document = message.media.document
                    content_type = getattr(document, 'mime_type', 'application/octet-stream')
                    
                    # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                    attributes = getattr(document, 'attributes', [])
                    for attr in attributes:
                        if hasattr(attr, 'file_name') and attr.file_name:
                            file_ext = os.path.splitext(attr.file_name)[1]
                            if file_ext:
                                ext = file_ext
                                break
            
            key = f"media/{channel_id}/{message.id}{ext}"
            mem_file = io.BytesIO()
            
            await client.download_media(message, file=mem_file)
            mem_file.seek(0)
            
            if media_type == 'photo':
                with Image.open(mem_file) as im: 
                    im = im.convert("RGB")
                    buf = io.BytesIO()
                    im.save(buf, format="WEBP", quality=80)
                    buf.seek(0)
                    mem_file = buf
                    
            s3_client.upload_fileobj(mem_file, S3_BUCKET_NAME, key, ExtraArgs={'ContentType': content_type})
            media_data["type"] = media_type
            media_data["url"] = f"https://{S3_BUCKET_NAME}.s3.{S3_REGION}.amazonaws.com/{key}"
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ thumbnail –¥–ª—è –≤–∏–¥–µ–æ
            if media_type == 'video' and isinstance(message.media, types.MessageMediaDocument):
                document = message.media.document
                if document and hasattr(document, 'thumbs') and document.thumbs: # type: ignore
                    try:
                        thumb_key = f"media/{channel_id}/{message.id}_thumb.webp"
                        thumb_in_memory = io.BytesIO()
                        
                        # –°–∫–∞—á–∏–≤–∞–µ–º thumbnail (–ø–æ—Å–ª–µ–¥–Ω–∏–π = –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
                        await client.download_media(message, thumb=-1, file=thumb_in_memory)
                        thumb_in_memory.seek(0)
                        
                        if thumb_in_memory.getbuffer().nbytes > 0:
                            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WebP
                            with Image.open(thumb_in_memory) as im:
                                im = im.convert("RGB")
                                output_buffer = io.BytesIO()
                                im.save(output_buffer, format="WEBP", quality=75)
                                output_buffer.seek(0)
                                
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º thumbnail –≤ S3
                            s3_client.upload_fileobj(
                                output_buffer, 
                                S3_BUCKET_NAME, 
                                thumb_key, 
                                ExtraArgs={'ContentType': 'image/webp'}
                            )
                            
                            media_data["thumbnail_url"] = f"https://{S3_BUCKET_NAME}.s3.{S3_REGION}.amazonaws.com/{thumb_key}"
                            logging.debug(f"‚úÖ Thumbnail –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è –≤–∏–¥–µ–æ {message.id}")
                        
                    except Exception as thumb_error:
                        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å thumbnail –¥–ª—è –≤–∏–¥–µ–æ {message.id}: {thumb_error}")
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ thumbnail
            
        return message.id, media_data
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ–¥–∏–∞ –¥–ª—è –ø–æ—Å—Ç–∞ {message.id}: {e}", exc_info=True)
        return message.id, None
    
async def create_post_dict(message: types.Message, channel_id: int) -> dict:
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∞–∫—Ü–∏–π
    reactions = [
        {
            'count': r.count, 
            'emoticon': getattr(r.reaction, 'emoticon', None), 
            'document_id': getattr(r.reaction, 'document_id', None)
        } 
        for r in (message.reactions.results if message.reactions else []) 
        if r.count > 0
    ]
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ forwarded_from
    forward_data = None
    if message.fwd_from:
        try:
            if hasattr(message.fwd_from, 'from_id') and message.fwd_from.from_id:
                if client is not None:
                    source_entity = await client.get_entity(message.fwd_from.from_id)
                    from_name = getattr(source_entity, 'title', getattr(source_entity, 'first_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫'))
                    username = getattr(source_entity, 'username', None)
                    raw_channel_id = getattr(source_entity, 'id', None)
                    channel_id_str = (
                        str(raw_channel_id)[4:] if raw_channel_id and str(raw_channel_id).startswith('-100') 
                        else str(raw_channel_id) if raw_channel_id else None
                    )
                    forward_data = {"from_name": from_name, "username": username, "channel_id": channel_id_str}
                else:
                    forward_data = {"from_name": "–ù–µ–¥–æ—Å—Ç—É–ø–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫", "username": None, "channel_id": None}
            elif hasattr(message.fwd_from, 'from_name'):
                forward_data = {"from_name": message.fwd_from.from_name, "username": None, "channel_id": None}
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å entity –¥–ª—è —Ä–µ–ø–æ—Å—Ç–∞: {e}")
            forward_data = {"from_name": "–ù–µ–¥–æ—Å—Ç—É–ø–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫", "username": None, "channel_id": None}
    
    return {
        "channel_id": channel_id,
        "message_id": message.id,
        "date": message.date,
        "text": process_text(getattr(message, 'text', None)),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ text
        "grouped_id": getattr(message, 'grouped_id', None),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ grouped_id
        "views": getattr(message, 'views', 0) or 0,  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ views
        "reactions": reactions,
        "forwarded_from": forward_data,
        "media": []
    }

async def fetch_posts_for_channel(channel: Channel, db_session: AsyncSession, post_limit: int):
    try:
        if client is None:  # ‚úÖ –î–û–ë–ê–í–ò–¢–¨ –ø—Ä–æ–≤–µ—Ä–∫—É client
            logging.error("Telethon client –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
            return
            
        entity = await get_cached_entity(channel)
        if not entity: 
            return
            
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ text –∏ media
        messages = [
            msg async for msg in client.iter_messages(entity, limit=post_limit) 
            if msg and (getattr(msg, 'text', None) or getattr(msg, 'media', None))
        ]
        
        if not messages:
            logging.info(f"–ù–µ—Ç –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –¥–ª—è ¬´{channel.title}¬ª")
            return
            
        posts_data = [await create_post_dict(msg, channel.id) for msg in messages]
        stmt = insert(Post).values(posts_data).on_conflict_do_nothing(index_elements=['channel_id', 'message_id']).returning(Post.message_id)
        result = await db_session.execute(stmt)
        new_message_ids = {row[0] for row in result.fetchall()}
        await db_session.commit()
        logging.info(f"–î–ª—è ¬´{channel.title}¬ª –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {len(messages)} –ø–æ—Å—Ç–æ–≤. –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö: {len(new_message_ids)}")
        await worker_stats.increment_posts(len(new_message_ids))
        
        if new_message_ids:
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ media
            new_messages_with_media = [
                msg for msg in messages 
                if msg.id in new_message_ids and getattr(msg, 'media', None)
            ]
            
            if new_messages_with_media:
                logging.info(f"–î–ª—è ¬´{channel.title}¬ª –∑–∞–ø—É—Å–∫–∞—é –∑–∞–≥—Ä—É–∑–∫—É {len(new_messages_with_media)} –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤...")
                for msg in new_messages_with_media:
                    try:
                        # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Å–µ—Å—Å–∏—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ–¥–∏–∞—Ñ–∞–π–ª–∞
                        async with session_maker() as media_session:
                            msg_id, media_data = await upload_media_to_s3(msg, channel.id)
                            if media_data:
                                update_stmt = update(Post).where(
                                    Post.channel_id == channel.id, 
                                    Post.message_id == msg_id
                                ).values(media=[media_data])
                                await media_session.execute(update_stmt)
                                await media_session.commit()
                                logging.debug(f"–ú–µ–¥–∏–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–ª—è –ø–æ—Å—Ç–∞ {msg_id}")
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ–¥–∏–∞ –¥–ª—è –ø–æ—Å—Ç–∞ {msg.id}: {e}")
                        continue
                        
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ ¬´{channel.title}¬ª: {e}", exc_info=True)
        await worker_stats.increment_errors()
        await db_session.rollback()

async def process_channel_safely(channel: Channel, semaphore: asyncio.Semaphore):
    async with semaphore, session_maker() as session:
        await fetch_posts_for_channel(channel, session, POST_LIMIT)
async def periodic_tasks_runner():
    while not shutdown_event.is_set():
        logging.info("–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –ø–æ—Å—Ç–æ–≤...")
        async with session_maker() as session:
            channels = (await session.execute(select(Channel).join(Subscription).distinct())).scalars().all()
        await worker_stats.set_channels(len(channels))
        if channels:
            semaphore = asyncio.Semaphore(15)
            await asyncio.gather(*[process_channel_safely(ch, semaphore) for ch in channels])
        logging.info("–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
        try: await asyncio.wait_for(shutdown_event.wait(), timeout=SLEEP_TIME)
        except asyncio.TimeoutError: pass
        
async def listen_for_new_channel_tasks():
    if not redis_publisher: 
        logging.warning("‚ùå Redis publisher –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω - –Ω–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!")
        logging.warning(f"‚ùå REDIS_URL = {REDIS_URL}")  # –î–û–ë–ê–í–ò–¢–¨ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        return
    
    logging.info("üîÑ –í–æ—Ä–∫–µ—Ä —Å–ª—É—à–∞–µ—Ç –∑–∞–¥–∞—á–∏ –Ω–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤...")
    
    try:
        redis_client = await redis_publisher.get_connection()
        logging.info("‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è —Å–ª—É—à–∞–Ω–∏—è –∑–∞–¥–∞—á")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis: {e}")
        return
    
    while not shutdown_event.is_set():
        try:
            logging.debug("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á –∏–∑ Redis...")  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
            
            task_raw = await redis_client.brpop("new_channel_tasks", timeout=1) # type: ignore
            
            if not task_raw: 
                continue
                
            logging.info(f"üì® –ü–æ–ª—É—á–µ–Ω—ã raw –¥–∞–Ω–Ω—ã–µ –∏–∑ Redis: {task_raw}")  # –î–û–ë–ê–í–ò–¢–¨
            
            task = json.loads(task_raw[1])
            channel_id = int(task.get("channel_id"))
            chat_id = int(task.get("user_chat_id"))
            title = task.get("channel_title")
            
            logging.info(f"üÜï –ù–û–í–´–ô –ö–ê–ù–ê–õ: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∫–∞–Ω–∞–ª ¬´{title}¬ª (ID: {channel_id}) –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {chat_id}")
            
            async with session_maker() as session:
                channel = await session.get(Channel, channel_id)
                if channel:
                    logging.info(f"üì• –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –ø–æ—Å—Ç–æ–≤ –∏–∑ ¬´{title}¬ª...")
                    
                    entity = await get_cached_entity(channel)
                    if entity and client is not None:
                        logging.info(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –∞–≤–∞—Ç–∞—Ä –¥–ª—è ¬´{title}¬ª...")
                        avatar_url = await upload_avatar_to_s3(client, entity)
                        if avatar_url: 
                            channel.avatar_url = avatar_url
                            session.add(channel)
                            await session.commit()
                            logging.info(f"‚úÖ –ê–≤–∞—Ç–∞—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è ¬´{title}¬ª")
                    
                    await fetch_posts_for_channel(channel, session, POST_LIMIT)
                    
                    # –û–¢–ü–†–ê–í–ö–ê –£–í–ï–î–û–ú–õ–ï–ù–ò–Ø
                    completion = {"user_chat_id": chat_id, "channel_title": title}
                    await redis_publisher.publish("task_completion_notifications", json.dumps(completion))
                    logging.info(f"üéâ –ö–∞–Ω–∞–ª ¬´{title}¬ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {chat_id}")
                else:
                    logging.error(f"‚ùå –ö–∞–Ω–∞–ª —Å ID {channel_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö!")
                    
        except asyncio.CancelledError: 
            logging.info("üõë Redis listener –ø–æ–ª—É—á–∏–ª —Å–∏–≥–Ω–∞–ª –æ—Ç–º–µ–Ω—ã")
            raise
        except asyncio.TimeoutError: 
            continue
        except json.JSONDecodeError as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Redis-—Å–ª—É—à–∞—Ç–µ–ª–µ: {e}", exc_info=True)
            await worker_stats.increment_errors()
            await asyncio.sleep(1)
    
    logging.info("üõë Redis listener –∑–∞–≤–µ—Ä—à–µ–Ω")

async def main():
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    await create_db()
    logging.info("–í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω.")
    
    if not client: 
        logging.critical("‚ùå Telethon –∫–ª–∏–µ–Ω—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
        return
    
    # –î–û–ë–ê–í–ò–¢–¨: –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis
    if not redis_publisher:
        logging.warning("‚ö†Ô∏è Redis –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω - –Ω–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
        logging.warning(f"‚ö†Ô∏è REDIS_URL = {os.getenv('REDIS_URL')}")
    else:
        logging.info("‚úÖ Redis –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    async with client:
        logging.info("‚úÖ –ö–ª–∏–µ–Ω—Ç Telethon —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω.")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏
        tasks = [
            asyncio.create_task(periodic_tasks_runner(), name="periodic_tasks"),
        ]
        
        if redis_publisher:
            tasks.append(asyncio.create_task(listen_for_new_channel_tasks(), name="redis_listener"))
            logging.info("üîÑ –ó–∞–ø—É—Å–∫–∞—é Redis listener...")
        else:
            logging.warning("‚ö†Ô∏è Redis listener –ù–ï –∑–∞–ø—É—â–µ–Ω - –Ω–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –Ω–µ –±—É–¥—É—Ç")
        
        await asyncio.gather(*tasks)
    
    if redis_publisher: 
        await redis_publisher.close()
    
    logging.info("‚úÖ –í–æ—Ä–∫–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")

# ‚úÖ –î–û–ë–ê–í–ò–¢–¨ –¢–û–ß–ö–£ –í–•–û–î–ê:
if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫–∞—é main()...")
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("üõë –í–æ—Ä–∫–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"üí• –§–ê–¢–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê –≤ main(): {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("üèÅ –í–æ—Ä–∫–µ—Ä –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")