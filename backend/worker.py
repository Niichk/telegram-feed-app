import asyncio
import logging
import os
import sys
import boto3
import io
import time
import bleach
import signal
import json
import redis.asyncio as aioredis
from typing import Dict, Any
from dotenv import load_dotenv
from telethon import TelegramClient, types
from telethon.errors import ChannelPrivateError, FloodWaitError
from sqlalchemy import select, distinct, update
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.dialects.postgresql import insert
from collections import defaultdict
from os.path import splitext

from database.engine import session_maker, create_db
from database.models import Channel, Post, BackfillRequest, Subscription
from telethon.sessions import StringSession
from PIL import Image
from html import escape
from markdown_it import MarkdownIt

print("üîÑ WORKER.PY –ó–ê–ì–†–£–ñ–ê–ï–¢–°–Ø...")
print(f"Python version: {sys.version}")

# ‚úÖ –ï–î–ò–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–ï–†–ï–ú–ï–ù–ù–´–•
try:
    print("üìã –ó–∞–≥—Ä—É–∂–∞—é –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    load_dotenv()
    
    print("üîç –ü—Ä–æ–≤–µ—Ä—è—é –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    
    API_ID_STR = os.getenv("API_ID")
    API_HASH = os.getenv("API_HASH") 
    SESSION_STRING = os.getenv("TELETHON_SESSION")
    REDIS_URL = os.getenv("REDIS_URL") or os.getenv("REDIS_PUBLIC_URL")
    S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")
    S3_REGION = os.getenv("S3_REGION")
    AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
    AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
    
    print(f"  API_ID: {'‚úÖ' if API_ID_STR else '‚ùå'}")
    print(f"  API_HASH: {'‚úÖ' if API_HASH else '‚ùå'}")
    print(f"  SESSION_STRING: {'‚úÖ' if SESSION_STRING else '‚ùå'}")
    print(f"  REDIS_URL: {'‚úÖ' if REDIS_URL else '‚ùå'}")
    print(f"  S3_BUCKET_NAME: {'‚úÖ' if S3_BUCKET_NAME else '‚ùå'}")
    
    # –ü–∞—Ä—Å–∏–Ω–≥ API_ID
    try:
        API_ID = int(API_ID_STR) if API_ID_STR else None
        print(f"  API_ID parsed: {'‚úÖ' if API_ID else '‚ùå'}")
    except Exception as e:
        print(f"  ‚ùå API_ID parse error: {e}")
        API_ID = None
    
    print("‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
except Exception as e:
    print(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –ó–ê–ì–†–£–ó–ö–ï –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# ‚úÖ –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ‚úÖ –ö–û–ù–°–¢–ê–ù–¢–´
POST_LIMIT, SLEEP_TIME = 20, 300
shutdown_event = asyncio.Event()

# ‚úÖ –ü–ê–†–°–ï–†–´ –ò –ö–õ–ò–ï–ù–¢–´
md_parser = MarkdownIt('commonmark', {'breaks': True, 'html': False, 'linkify': True})

# ‚úÖ –ï–î–ò–ù–´–ï –ö–õ–ê–°–°–´ (–ë–ï–ó –î–£–ë–õ–ò–†–û–í–ê–ù–ò–Ø)
class ThreadSafeEntityCache:
    def __init__(self, max_size: int = 500):
        self._cache: Dict[str, Any] = {}
        self._access_times: Dict[str, float] = {}
        self._locks: Dict[str, asyncio.Lock] = {}
        self._max_size = max_size
        self._main_lock = asyncio.Lock()
        
    async def get_entity(self, cache_key: str, fetch_func):
        if cache_key in self._cache:
            async with self._main_lock:
                self._access_times[cache_key] = time.time()
            return self._cache[cache_key]
            
        async with self._main_lock:
            if cache_key not in self._locks: 
                self._locks[cache_key] = asyncio.Lock()
            lock = self._locks[cache_key]
            
        async with lock:
            if cache_key in self._cache:
                async with self._main_lock: 
                    self._access_times[cache_key] = time.time()
                return self._cache[cache_key]
                
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –ë–ï–ó –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏, cleanup –æ—Ç–¥–µ–ª—å–Ω–æ
            should_cleanup = len(self._cache) >= self._max_size
            
            try:
                entity = await fetch_func()
                async with self._main_lock: 
                    self._cache[cache_key] = entity
                    self._access_times[cache_key] = time.time()
                
                # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: Cleanup –ü–û–°–õ–ï –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                if should_cleanup:
                    await self._cleanup_if_needed()
                    
                return entity
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è entity –¥–ª—è {cache_key}: {e}")
                return None
                
    async def _cleanup_if_needed(self):
        async with self._main_lock:
            if len(self._cache) >= self._max_size:
                to_remove = sorted(self._access_times.items(), key=lambda x: x[1])[:self._max_size // 5]
                for key, _ in to_remove:
                    self._cache.pop(key, None)
                    self._access_times.pop(key, None)
                    self._locks.pop(key, None)

class WorkerStats:
    def __init__(self):
        self.start_time = time.time()
        self.processed_channels, self.processed_posts, self.errors = 0, 0, 0
        self._lock = asyncio.Lock()
        
    async def increment_posts(self, count: int):
        async with self._lock: 
            self.processed_posts += count
            
    async def increment_errors(self, count: int = 1):
        async with self._lock: 
            self.errors += count
            
    async def set_channels(self, count: int):
        async with self._lock: 
            self.processed_channels = count
            
    async def get_stats(self) -> dict:
        async with self._lock:
            return {
                'start_time': self.start_time, 
                'processed_channels': self.processed_channels, 
                'processed_posts': self.processed_posts, 
                'errors': self.errors
            }

class RedisPublisher:
    def __init__(self, redis_url: str):
        self.redis_url = redis_url
        self._pool = None
        self._lock = asyncio.Lock()
        
    async def get_connection(self):
        if self._pool is None:
            async with self._lock:
                if self._pool is None: 
                    self._pool = aioredis.ConnectionPool.from_url(
                        self.redis_url, 
                        max_connections=20, 
                        retry_on_timeout=True
                    )
        return aioredis.Redis(connection_pool=self._pool)
        
    async def publish(self, channel: str, message: str):
        try: 
            conn = await self.get_connection()
            await conn.publish(channel, message)
        except Exception as e: 
            logging.error(f"Redis publish error: {e}")
            
    async def close(self):
        if self._pool: 
            await self._pool.disconnect()

# ‚úÖ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–õ–ò–ï–ù–¢–û–í (–ü–û–°–õ–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ö–õ–ê–°–°–û–í)
try:
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é –∫–ª–∏–µ–Ω—Ç—ã...")
    
    # Telethon client
    client = None
    if SESSION_STRING and API_ID is not None and API_HASH:
        try:
            client = TelegramClient(StringSession(SESSION_STRING), API_ID, API_HASH)
            print(f"  Telethon client: ‚úÖ")
        except Exception as e:
            print(f"  ‚ùå Telethon client error: {e}")
            client = None
    else:
        print(f"  Telethon client: ‚ùå (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç credentials)")

    # Redis publisher
    redis_publisher = None
    if REDIS_URL:
        try:
            redis_publisher = RedisPublisher(REDIS_URL)
            print(f"  Redis publisher: ‚úÖ")
        except Exception as e:
            print(f"  ‚ùå Redis publisher error: {e}")
            redis_publisher = None
    else:
        print(f"  Redis publisher: ‚ùå (REDIS_URL –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)")

    # S3 client
    s3_client = None
    if all([AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, S3_REGION]):
        try:
            s3_client = boto3.client(
                's3',
                aws_access_key_id=AWS_ACCESS_KEY_ID,
                aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
                region_name=S3_REGION
            )
            print(f"  S3 client: ‚úÖ")
        except Exception as e:
            print(f"  ‚ùå S3 client error: {e}")
            s3_client = None
    else:
        print(f"  S3 client: ‚ùå (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç AWS credentials)")
    
    print("‚úÖ worker.py —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
    
except Exception as e:
    print(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò –∫–ª–∏–µ–Ω—Ç–æ–≤: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# ‚úÖ –ì–õ–û–ë–ê–õ–¨–ù–´–ï INSTANCES
entity_cache = ThreadSafeEntityCache()
worker_stats = WorkerStats()
s3_semaphore = asyncio.Semaphore(10)

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def signal_handler(signum, frame): shutdown_event.set()
def process_text(text: str | None) -> str | None:
    if not text: return None
    try:
        html = md_parser.renderInline(text)
        return bleach.clean(html.replace('<a href', '<a target="_blank" rel="noopener noreferrer" href'), tags=['a', 'b', 'strong', 'i', 'em', 'pre', 'code', 'br', 's', 'u', 'blockquote'], attributes={'a': ['href', 'title', 'target', 'rel']})
    except Exception: return escape(text or "").replace('\n', '<br>')
async def get_cached_entity(channel: Channel):
    async def fetcher():
        if client is None:
            logging.error("Telethon client is not initialized.")
            return None
        entity = await client.get_entity(channel.username or int(channel.id))
        return entity[0] if isinstance(entity, list) else entity
    return await entity_cache.get_entity(str(channel.id), fetcher)

async def upload_avatar_to_s3(telethon_client: TelegramClient, channel_entity) -> str | None:
    if not s3_client or not S3_BUCKET_NAME or not S3_REGION:
        logging.debug("S3 –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∞–≤–∞—Ç–∞—Ä–æ–≤")
        return None
        
    try:
        file_key = f"avatars/{channel_entity.id}.jpg"
        file_in_memory = io.BytesIO()
        
        await telethon_client.download_profile_photo(channel_entity, file=file_in_memory)
        if file_in_memory.getbuffer().nbytes == 0: 
            return None
            
        file_in_memory.seek(0)
        s3_client.upload_fileobj(
            file_in_memory, 
            S3_BUCKET_NAME, 
            file_key, 
            ExtraArgs={'ContentType': 'image/jpeg'}
        )
        return f"https://{S3_BUCKET_NAME}.s3.{S3_REGION}.amazonaws.com/{file_key}"
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è {channel_entity.id}: {e}")
        await worker_stats.increment_errors()  # ‚úÖ –¢–µ–ø–µ—Ä—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
        return None

# --- –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò –í–û–†–ö–ï–†–ê ---
async def upload_media_to_s3(message: types.Message, channel_id: int) -> tuple[int, dict | None]:
    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    if client is None:
        logging.error("Telethon client –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
        return message.id, None
        
    if not s3_client or not S3_BUCKET_NAME or not S3_REGION:
        logging.debug("S3 –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ–¥–∏–∞")
        return message.id, None
        
    media_data, media_type = {}, None
    
    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ document
    if isinstance(message.media, types.MessageMediaPhoto):
        media_type = 'photo'
    elif isinstance(message.media, types.MessageMediaDocument):
        doc = message.media.document
        if not doc:
            return message.id, None
        if getattr(doc, 'size', 0) > 60 * 1024 * 1024:
            logging.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞—é –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª {message.id}: {getattr(doc, 'size', 0)} bytes")
            return message.id, None # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –±–æ–ª—å—à–µ 60MB

        mime_type = getattr(doc, 'mime_type', '').lower()
        is_sticker = any(isinstance(attr, types.DocumentAttributeSticker) for attr in getattr(doc, 'attributes', []))

        if is_sticker:
            media_type = 'sticker'
        elif mime_type.startswith('audio/'):
            media_type = 'audio'
        elif mime_type.startswith('video/'):
            media_type = 'video'
        elif mime_type == 'image/gif':
            media_type = 'gif'

    if not media_type: 
        return message.id, None
        
    try:
        async with s3_semaphore:
            ext = '.dat'
            content_type = 'application/octet-stream'

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏ —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            if media_type == 'photo':
                ext, content_type = '.webp', 'image/webp'
            elif media_type == 'gif':
                ext, content_type = '.gif', 'image/gif'
            elif media_type == 'sticker':
                ext, content_type = '.webp', 'image/webp'
            elif media_type in ('video', 'audio'):
                if message.media.document:
                    doc = message.media.document
                    content_type = getattr(doc, 'mime_type', content_type)
                    file_name_attr = next((attr for attr in getattr(doc, 'attributes', []) if hasattr(attr, 'file_name')), None)
                    if file_name_attr and hasattr(file_name_attr, 'file_name'):
                        file_ext = os.path.splitext(file_name_attr.file_name)[1]
                        if file_ext:
                            ext = file_ext

            key = f"media/{channel_id}/{message.id}{ext}"
            mem_file = io.BytesIO()
            
            logging.debug(f"–°–∫–∞—á–∏–≤–∞—é –º–µ–¥–∏–∞ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {message.id}")
            await client.download_media(message, file=mem_file)
            mem_file.seek(0)
            
            if media_type == 'photo':
                try:
                    with Image.open(mem_file) as im: 
                        im = im.convert("RGB")
                        buf = io.BytesIO()
                        im.save(buf, format="WEBP", quality=80)
                        buf.seek(0)
                        mem_file = buf
                except Exception as img_error:
                    logging.warning(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {message.id}: {img_error}")
                    return message.id, None
                    
            logging.debug(f"–ó–∞–≥—Ä—É–∂–∞—é –≤ S3: {key}")
            s3_client.upload_fileobj(mem_file, S3_BUCKET_NAME, key, ExtraArgs={'ContentType': content_type})
            media_data["type"] = media_type
            media_data["url"] = f"https://{S3_BUCKET_NAME}.s3.{S3_REGION}.amazonaws.com/{key}"
            
            # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ thumbnail –¥–ª—è –≤–∏–¥–µ–æ
            if media_type == 'video' and isinstance(message.media, types.MessageMediaDocument):
                document = message.media.document
                if document and hasattr(document, 'thumbs') and document.thumbs:
                    try:
                        thumb_key = f"media/{channel_id}/{message.id}_thumb.webp"
                        thumb_in_memory = io.BytesIO()
                        
                        logging.debug(f"–°–∫–∞—á–∏–≤–∞—é thumbnail –¥–ª—è –≤–∏–¥–µ–æ {message.id}")
                        await client.download_media(message, thumb=-1, file=thumb_in_memory)
                        thumb_in_memory.seek(0)
                        
                        if thumb_in_memory.getbuffer().nbytes > 0:
                            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WebP
                            try:
                                with Image.open(thumb_in_memory) as im:
                                    im = im.convert("RGB")
                                    output_buffer = io.BytesIO()
                                    im.save(output_buffer, format="WEBP", quality=75)
                                    output_buffer.seek(0)
                                    
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º thumbnail –≤ S3
                                s3_client.upload_fileobj(
                                    output_buffer, 
                                    S3_BUCKET_NAME, 
                                    thumb_key, 
                                    ExtraArgs={'ContentType': 'image/webp'}
                                )
                                
                                media_data["thumbnail_url"] = f"https://{S3_BUCKET_NAME}.s3.{S3_REGION}.amazonaws.com/{thumb_key}"
                                logging.debug(f"‚úÖ Thumbnail –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è –≤–∏–¥–µ–æ {message.id}")
                            except Exception as convert_error:
                                logging.warning(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ thumbnail –¥–ª—è {message.id}: {convert_error}")
                        
                    except Exception as thumb_error:
                        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å thumbnail –¥–ª—è –≤–∏–¥–µ–æ {message.id}: {thumb_error}")
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ thumbnail
            
        logging.debug(f"‚úÖ –ú–µ–¥–∏–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {message.id}: {media_data}")
        return message.id, media_data
        
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ–¥–∏–∞ –¥–ª—è –ø–æ—Å—Ç–∞ {message.id}: {e}", exc_info=True)
        await worker_stats.increment_errors()
        return message.id, None
    
async def create_post_dict(message: types.Message, channel_id: int) -> dict:
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∞–∫—Ü–∏–π
    reactions = [
        {
            'count': r.count, 
            'emoticon': getattr(r.reaction, 'emoticon', None), 
            'document_id': getattr(r.reaction, 'document_id', None)
        } 
        for r in (message.reactions.results if message.reactions else []) 
        if r.count > 0
    ]
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ forwarded_from
    forward_data = None
    if message.fwd_from:
        try:
            if hasattr(message.fwd_from, 'from_id') and message.fwd_from.from_id:
                if client is not None:
                    source_entity = await client.get_entity(message.fwd_from.from_id)
                    from_name = getattr(source_entity, 'title', getattr(source_entity, 'first_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫'))
                    username = getattr(source_entity, 'username', None)
                    raw_channel_id = getattr(source_entity, 'id', None)
                    channel_id_str = (
                        str(raw_channel_id)[4:] if raw_channel_id and str(raw_channel_id).startswith('-100') 
                        else str(raw_channel_id) if raw_channel_id else None
                    )
                    forward_data = {"from_name": from_name, "username": username, "channel_id": channel_id_str}
                else:
                    forward_data = {"from_name": "–ù–µ–¥–æ—Å—Ç—É–ø–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫", "username": None, "channel_id": None}
            elif hasattr(message.fwd_from, 'from_name'):
                forward_data = {"from_name": message.fwd_from.from_name, "username": None, "channel_id": None}
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å entity –¥–ª—è —Ä–µ–ø–æ—Å—Ç–∞: {e}")
            forward_data = {"from_name": "–ù–µ–¥–æ—Å—Ç—É–ø–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫", "username": None, "channel_id": None}
    
    return {
        "channel_id": channel_id,
        "message_id": message.id,
        "date": message.date,
        "text": process_text(getattr(message, 'text', None)),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ text
        "grouped_id": getattr(message, 'grouped_id', None),  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ grouped_id
        "views": getattr(message, 'views', 0) or 0,  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ views
        "reactions": reactions,
        "forwarded_from": forward_data,
        "media": []
    }

async def fetch_posts_for_channel(channel: Channel, db_session: AsyncSession, post_limit: int):
    try:
        if client is None:
            logging.error("Telethon client –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
            return
            
        entity = await get_cached_entity(channel)
        if not entity: 
            return
        
        # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram
        messages = [
            msg async for msg in client.iter_messages(entity, limit=post_limit) 
            if msg and (getattr(msg, 'text', None) or getattr(msg, 'media', None))
        ]
        
        if not messages:
            return

        # –®–∞–≥ 2: –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∞–ª—å–±–æ–º—ã
        grouped_messages = defaultdict(list)
        for msg in messages:
            key = msg.grouped_id or msg.id 
            grouped_messages[key].append(msg)

        # –®–∞–≥ 3: –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        posts_to_prepare = []
        for group_id, message_group in grouped_messages.items():
            message_group.sort(key=lambda m: m.id)
            main_message = message_group[0]
            
            # –°—Ä–∞–∑—É —Å–æ–∑–¥–∞–µ–º "—Å–∫–µ–ª–µ—Ç" –ø–æ—Å—Ç–∞, —á—Ç–æ–±—ã –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º –¥–æ–±–∞–≤–∏—Ç—å –≤ –Ω–µ–≥–æ –º–µ–¥–∏–∞
            post_data = await create_post_dict(main_message, channel.id)
            posts_to_prepare.append({
                "post_data": post_data,
                "messages": message_group
            })

        if not posts_to_prepare:
            return

        # –®–∞–≥ 4: –°–∫–∞—á–∏–≤–∞–µ–º –º–µ–¥–∏–∞ –¢–û–õ–¨–ö–û –¥–ª—è —Ç–µ—Ö –ø–æ—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∞–∑–µ
        main_message_ids = [p['post_data']['message_id'] for p in posts_to_prepare]
        
        stmt_select = select(Post.message_id).where(
            Post.channel_id == channel.id,
            Post.message_id.in_(main_message_ids)
        )
        result = await db_session.execute(stmt_select)
        existing_message_ids = {row[0] for row in result.fetchall()}

        posts_to_insert = []
        for item in posts_to_prepare:
            # –ï—Å–ª–∏ –ø–æ—Å—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –º—ã –µ–≥–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if item['post_data']['message_id'] in existing_message_ids:
                continue

            # –ï—Å–ª–∏ –ø–æ—Å—Ç –Ω–æ–≤—ã–π, —Å–∫–∞—á–∏–≤–∞–µ–º –¥–ª—è –Ω–µ–≥–æ –º–µ–¥–∏–∞
            media_list = []
            message_group = item['messages']
            if any(getattr(msg, 'media', None) for msg in message_group):
                media_upload_tasks = [
                    upload_media_to_s3(msg_in_group, channel.id)
                    for msg_in_group in message_group if getattr(msg_in_group, 'media', None)
                ]
                media_results = await asyncio.gather(*media_upload_tasks)
                media_list = [media for _, media in media_results if media]

            final_post_data = item['post_data']
            final_post_data['media'] = media_list
            posts_to_insert.append(final_post_data)

        if not posts_to_insert:
            logging.info(f"–î–ª—è ¬´{channel.title}¬ª –Ω–µ—Ç –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤.")
            return

        # –®–∞–≥ 5: –í—Å—Ç–∞–≤–ª—è–µ–º –≤ –ë–î, –ø–æ–∑–≤–æ–ª—è—è –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Å–∞–º–æ–π —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è —Å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞–º–∏
        stmt_insert = insert(Post).values(posts_to_insert)
        
        # –í–û–¢ –ö–õ–Æ–ß–ï–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï:
        stmt_insert = stmt_insert.on_conflict_do_nothing(
            index_elements=['channel_id', 'message_id']
        )
        
        await db_session.execute(stmt_insert)
        await db_session.commit()

        logging.info(f"–î–ª—è ¬´{channel.title}¬ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(grouped_messages)} –ø–æ—Å—Ç–æ–≤/–≥—Ä—É–ø–ø. –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö: {len(posts_to_insert)}")
        if posts_to_insert:
            await worker_stats.increment_posts(len(posts_to_insert))
            
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ ¬´{channel.title}¬ª: {e}", exc_info=True)
        await worker_stats.increment_errors()
        await db_session.rollback()

async def process_channel_safely(channel: Channel, semaphore: asyncio.Semaphore):
    async with semaphore, session_maker() as session:
        await fetch_posts_for_channel(channel, session, POST_LIMIT)

async def periodic_tasks_runner():
    while not shutdown_event.is_set():
        logging.info("–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –ø–æ—Å—Ç–æ–≤...")
        async with session_maker() as session:
            channels = (await session.execute(select(Channel).join(Subscription).distinct())).scalars().all()
        await worker_stats.set_channels(len(channels))
        if channels:
            semaphore = asyncio.Semaphore(15)
            await asyncio.gather(*[process_channel_safely(ch, semaphore) for ch in channels])
        logging.info("–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
        try: await asyncio.wait_for(shutdown_event.wait(), timeout=SLEEP_TIME)
        except asyncio.TimeoutError: pass
        
async def listen_for_new_channel_tasks():
    if not redis_publisher: 
        logging.warning("‚ùå Redis publisher –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω - –Ω–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!")
        logging.warning(f"‚ùå REDIS_URL = {REDIS_URL}")  # –î–û–ë–ê–í–ò–¢–¨ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        return
    
    logging.info("üîÑ –í–æ—Ä–∫–µ—Ä —Å–ª—É—à–∞–µ—Ç –∑–∞–¥–∞—á–∏ –Ω–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–æ–≤...")
    
    try:
        redis_client = await redis_publisher.get_connection()
        logging.info("‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è —Å–ª—É—à–∞–Ω–∏—è –∑–∞–¥–∞—á")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis: {e}")
        return
    
    while not shutdown_event.is_set():
        try:
            logging.debug("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á –∏–∑ Redis...")  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
            
            task_raw = await redis_client.brpop("new_channel_tasks", timeout=1) # type: ignore
            
            if not task_raw: 
                continue
                
            logging.info(f"üì® –ü–æ–ª—É—á–µ–Ω—ã raw –¥–∞–Ω–Ω—ã–µ –∏–∑ Redis: {task_raw}")  # –î–û–ë–ê–í–ò–¢–¨
            
            task = json.loads(task_raw[1])
            channel_id = int(task.get("channel_id"))
            chat_id = int(task.get("user_chat_id"))
            title = task.get("channel_title")
            
            logging.info(f"üÜï –ù–û–í–´–ô –ö–ê–ù–ê–õ: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∫–∞–Ω–∞–ª ¬´{title}¬ª (ID: {channel_id}) –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {chat_id}")
            
            async with session_maker() as session:
                channel = await session.get(Channel, channel_id)
                if channel:
                    logging.info(f"üì• –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –ø–æ—Å—Ç–æ–≤ –∏–∑ ¬´{title}¬ª...")
                    
                    entity = await get_cached_entity(channel)
                    if entity and client is not None:
                        logging.info(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–∞—é –∞–≤–∞—Ç–∞—Ä –¥–ª—è ¬´{title}¬ª...")
                        avatar_url = await upload_avatar_to_s3(client, entity)
                        if avatar_url: 
                            channel.avatar_url = avatar_url
                            session.add(channel)
                            await session.commit()
                            logging.info(f"‚úÖ –ê–≤–∞—Ç–∞—Ä –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è ¬´{title}¬ª")
                    
                    await fetch_posts_for_channel(channel, session, POST_LIMIT)
                    
                    # –û–¢–ü–†–ê–í–ö–ê –£–í–ï–î–û–ú–õ–ï–ù–ò–Ø
                    completion = {"user_chat_id": chat_id, "channel_title": title}
                    await redis_publisher.publish("task_completion_notifications", json.dumps(completion))
                    logging.info(f"üéâ –ö–∞–Ω–∞–ª ¬´{title}¬ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {chat_id}")
                else:
                    logging.error(f"‚ùå –ö–∞–Ω–∞–ª —Å ID {channel_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö!")
                    
        except asyncio.CancelledError: 
            logging.info("üõë Redis listener –ø–æ–ª—É—á–∏–ª —Å–∏–≥–Ω–∞–ª –æ—Ç–º–µ–Ω—ã")
            raise
        except asyncio.TimeoutError: 
            continue
        except json.JSONDecodeError as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Redis-—Å–ª—É—à–∞—Ç–µ–ª–µ: {e}", exc_info=True)
            await worker_stats.increment_errors()
            await asyncio.sleep(1)
    
    logging.info("üõë Redis listener –∑–∞–≤–µ—Ä—à–µ–Ω")

async def main():
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    await create_db()
    logging.info("–í–æ—Ä–∫–µ—Ä –∑–∞–ø—É—â–µ–Ω.")
    
    if not client: 
        logging.critical("‚ùå Telethon –∫–ª–∏–µ–Ω—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
        return
    
    # –î–û–ë–ê–í–ò–¢–¨: –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis
    if not redis_publisher:
        logging.warning("‚ö†Ô∏è Redis –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω - –Ω–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–µ –±—É–¥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
        logging.warning(f"‚ö†Ô∏è REDIS_URL = {os.getenv('REDIS_URL')}")
    else:
        logging.info("‚úÖ Redis –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    async with client:
        logging.info("‚úÖ –ö–ª–∏–µ–Ω—Ç Telethon —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω.")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏
        tasks = [
            asyncio.create_task(periodic_tasks_runner(), name="periodic_tasks"),
        ]
        
        if redis_publisher:
            tasks.append(asyncio.create_task(listen_for_new_channel_tasks(), name="redis_listener"))
            logging.info("üîÑ –ó–∞–ø—É—Å–∫–∞—é Redis listener...")
        else:
            logging.warning("‚ö†Ô∏è Redis listener –ù–ï –∑–∞–ø—É—â–µ–Ω - –Ω–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –Ω–µ –±—É–¥—É—Ç")
        
        await asyncio.gather(*tasks)
    
    if redis_publisher: 
        await redis_publisher.close()
    
    logging.info("‚úÖ –í–æ—Ä–∫–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É.")

# ‚úÖ –î–û–ë–ê–í–ò–¢–¨ –¢–û–ß–ö–£ –í–•–û–î–ê:
if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫–∞—é main()...")
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("üõë –í–æ—Ä–∫–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"üí• –§–ê–¢–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê –≤ main(): {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("üèÅ –í–æ—Ä–∫–µ—Ä –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")